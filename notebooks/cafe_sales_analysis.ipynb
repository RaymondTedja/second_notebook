{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b46938",
   "metadata": {},
   "source": [
    "# Business Consultant: Retail Operations Pipeline\n",
    "Objective: Automate the ingestion, cleaning, and strategic analysis of transaction data for a high-volume cafe.\n",
    "\n",
    "Datasheet: https://www.kaggle.com/datasets/ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training/data\n",
    "\n",
    "This dataset is released under the CC BY-SA 4.0 License. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e3bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install kagglehub pandas matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a87ce8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cafe Analytics class. \n",
    "# All the analytics function will be defined in this class.\n",
    "\n",
    "class CafeAnalytics:\n",
    "    def __init__(self, dataset_handle):\n",
    "        self.handle = dataset_handle\n",
    "        self.df = None\n",
    "        self.path = None\n",
    "\n",
    "    def ingest_data(self):\n",
    "        print(f\"--- Ingesting data from: {self.handle} ---\")\n",
    "        self.path = kagglehub.dataset_download(self.handle)\n",
    "        \n",
    "        # Dynamic search for the CSV\n",
    "        csv_files = [f for f in os.listdir(self.path) if f.endswith('.csv')]\n",
    "        full_path = os.path.join(self.path, csv_files[0])\n",
    "        self.df = pd.read_csv(full_path)\n",
    "        print(f\"Success! Loaded {len(self.df)} records.\")\n",
    "\n",
    "    def audit_data(self):\n",
    "        # A quick report for the 'Client'\n",
    "        print(f\"\\n--- Business Data Audit ---\")\n",
    "        print(f\"Missing Values: {self.df.isnull().sum().sum()}\")\n",
    "        print(f\"Unique Products: {self.df['Item'].nunique()}\")\n",
    "        display(self.df.describe())\n",
    "\n",
    "    def pre_clean_audit(self):\n",
    "        if self.df is None:\n",
    "            print(\"Error: Load data first!\")\n",
    "            return\n",
    "\n",
    "        # 1. Financial Calculations\n",
    "        avg_spend = pd.to_numeric(self.df['Total Spent'], errors='coerce').mean()\n",
    "        \n",
    "        # Identify the 'Junk' (Standardizing to lower case just for the check)\n",
    "        \n",
    "        # 1. Standardize the text (handles spaces and casing)\n",
    "        clean_items = self.df['Item'].astype(str).str.strip().str.upper()\n",
    "\n",
    "        # 2. Check for the \"Keywords\" AND check for \"Empty Strings\"\n",
    "        mask_junk = (clean_items.isin(['UNKNOWN', 'ERROR', 'NAN', 'NONE', ''])) | (clean_items == \"\")\n",
    "        junk_df = self.df[mask_junk]\n",
    "        \n",
    "        junk_total_spent = pd.to_numeric(junk_df['Total Spent'], errors='coerce')\n",
    "        lost_revenue = junk_total_spent.sum()\n",
    "\n",
    "        mask_nulls = self.df['Item'].isna()\n",
    "        nulls_df = self.df[mask_nulls]\n",
    "\n",
    "        nulls_total_spent = pd.to_numeric(nulls_df['Total Spent'], errors='coerce')\n",
    "        null_lost_revenue = nulls_total_spent.sum()\n",
    "\n",
    "        total_rows = len(self.df)\n",
    "        junk_rows_count = len(junk_df)\n",
    "        junk_percent = (junk_rows_count / total_rows) * 100\n",
    "\n",
    "        # 2. The Consultant Report\n",
    "        print(\"======= PRE-CLEANING STRATEGIC AUDIT =======\")\n",
    "        print(f\"Total Transactions Audited: {total_rows:,}\")\n",
    "        print(f\"Average Transaction Value: ${avg_spend:.2f}\")\n",
    "        print(\"-\" * 44)\n",
    "        print(f\"CRITICAL ALERT: 'Dark Data' detected.\")\n",
    "        print(f\"Unidentified Items (UNKNOWN/ERROR): {junk_rows_count} rows\")\n",
    "        \n",
    "        print(f\"Data Corruption Rate: {junk_percent:.2f}%\")\n",
    "        print(f\"Revenue at Risk: ${lost_revenue:,.2f}\")\n",
    "        print(f\"Revenue at Risk from empty item name: ${null_lost_revenue:,.2f}\")\n",
    "        print(\"-\" * 44)\n",
    "        print(\"Observation: This revenue is currently untraceable to specific \")\n",
    "        print(\"products, preventing accurate inventory and marketing decisions.\")\n",
    "        print(\"============================================\")\n",
    "        \n",
    "        # Store these stats if you want to use them for the AI later\n",
    "        self.pre_clean_stats = {\n",
    "            \"lost_revenue\": lost_revenue,\n",
    "            \"junk_percent\": junk_percent\n",
    "        }\n",
    "\n",
    "\n",
    "    def clean_data(self):\n",
    "        print(\"--- Starting Data Sanitization ---\")\n",
    "        \n",
    "        # 1. Capture original size to report how much \"junk\" we removed\n",
    "        initial_rows = len(self.df)\n",
    "        \n",
    "        # 2. Standardize Categories (Fixes 'coffee' vs 'Coffee ')\n",
    "        if 'Item' in self.df.columns:\n",
    "            self.df['Item'] = self.df['Item'].str.strip().str.title()\n",
    "        \n",
    "        # 3. Filter out \"Invalid\" entries (The 'Error' and 'Unknown' items)\n",
    "        # Consultants remove data that would \"pollute\" the final business strategy\n",
    "        self.df = self.df[~self.df['Item'].isin(['Error', 'Unknown'])]\n",
    "        \n",
    "        # 4. Handle Missing Prices (Imputation)\n",
    "        # Instead of deleting, we fill missing prices with the Median (the 'Safe' middle value)\n",
    "        if 'Price' in self.df.columns:\n",
    "            median_price = self.df['Price'].median()\n",
    "            self.df['Price'] = self.df['Price'].fillna(median_price)\n",
    "            \n",
    "        # Fill missing prices based on what the item actually is\n",
    "        #self.df['Price'] = self.df['Price'].fillna(self.df.groupby('Item')['Price'].transform('median'))\n",
    "\n",
    "\n",
    "        # 5. Final Report for the Client\n",
    "        final_rows = len(self.df)\n",
    "        removed = initial_rows - final_rows\n",
    "        print(f\"Sanitization Complete: Removed {removed} invalid rows.\")\n",
    "        print(f\"Data Health: 100% of remaining {final_rows} rows are standardized.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77121dab",
   "metadata": {},
   "source": [
    "# Input Phase\n",
    "\n",
    "This dataset is intentionally \"dirty,\" with missing values, inconsistent data, and errors introduced to provide a realistic scenario for data cleaning and exploratory data analysis (EDA). It can be used to practice cleaning techniques, data wrangling, and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "974fe68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ingesting data from: ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training ---\n",
      "Success! Loaded 10000 records.\n",
      "======= PRE-CLEANING STRATEGIC AUDIT =======\n",
      "Total Transactions Audited: 10,000\n",
      "Average Transaction Value: $8.92\n",
      "--------------------------------------------\n",
      "CRITICAL ALERT: 'Dark Data' detected.\n",
      "Unidentified Items (UNKNOWN/ERROR): 969 rows\n",
      "Data Corruption Rate: 9.69%\n",
      "Revenue at Risk: $8,140.00\n",
      "Revenue at Risk from empty item name: $2,929.00\n",
      "--------------------------------------------\n",
      "Observation: This revenue is currently untraceable to specific \n",
      "products, preventing accurate inventory and marketing decisions.\n",
      "============================================\n",
      "\n",
      "--- Business Data Audit ---\n",
      "Missing Values: 6826\n",
      "Unique Products: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000</td>\n",
       "      <td>9667</td>\n",
       "      <td>9862</td>\n",
       "      <td>9821</td>\n",
       "      <td>9827</td>\n",
       "      <td>7421</td>\n",
       "      <td>6735</td>\n",
       "      <td>9841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>TXN_9226047</td>\n",
       "      <td>Juice</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1171</td>\n",
       "      <td>2013</td>\n",
       "      <td>2429</td>\n",
       "      <td>979</td>\n",
       "      <td>2291</td>\n",
       "      <td>3022</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Transaction ID   Item Quantity Price Per Unit Total Spent  \\\n",
       "count           10000   9667     9862           9821        9827   \n",
       "unique          10000     10        7              8          19   \n",
       "top       TXN_9226047  Juice        5            3.0         6.0   \n",
       "freq                1   1171     2013           2429         979   \n",
       "\n",
       "        Payment Method  Location Transaction Date  \n",
       "count             7421      6735             9841  \n",
       "unique               5         4              367  \n",
       "top     Digital Wallet  Takeaway          UNKNOWN  \n",
       "freq              2291      3022              159  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item\n",
      "Juice       12.113375\n",
      "Coffee      12.051309\n",
      "Salad       11.875453\n",
      "Cake        11.782352\n",
      "Sandwich    11.699597\n",
      "Smoothie    11.337540\n",
      "Cookie      11.296162\n",
      "Tea         11.265129\n",
      "UNKNOWN      3.558498\n",
      "ERROR        3.020585\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Initialize\n",
    "dataset_handle = 'ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training'\n",
    "consultant_tool = CafeAnalytics(dataset_handle)\n",
    "\n",
    "# Run Ingestion\n",
    "consultant_tool.ingest_data()\n",
    "\n",
    "# Run pre clean audit\n",
    "consultant_tool.pre_clean_audit()\n",
    "\n",
    "# Run Audit\n",
    "consultant_tool.audit_data()\n",
    "\n",
    "# Set normalize=True to get decimals (0.60 = 60%)\n",
    "print(f'{consultant_tool.df['Item'].value_counts(normalize=True) * 100}')\n",
    "\n",
    "#consultant_tool.df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5f3c08",
   "metadata": {},
   "source": [
    "Item might contain missing or invalid values  \n",
    "Quantity might contain missing or invalid values  \n",
    "Price per unit might contain missing or invalid values  \n",
    "Payment method might contain missing or invalid values  \n",
    "Location might contain missing or invalid values  \n",
    "Transaction date might contain missing or invalid values  \n",
    "\n",
    "Payment and Location have a lot of null values (more than 20%)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa19bbb",
   "metadata": {},
   "source": [
    "# Cleaning Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d189b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Sanitization ---\n",
      "Sanitization Complete: Removed 636 invalid rows.\n",
      "Data Health: 100% of remaining 9364 rows are standardized.\n",
      "Transaction ID         0\n",
      "Item                 333\n",
      "Quantity             124\n",
      "Price Per Unit       165\n",
      "Total Spent          158\n",
      "Payment Method      2412\n",
      "Location            3049\n",
      "Transaction Date     149\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "consultant_tool.clean_data()\n",
    "\n",
    "print(consultant_tool.df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffd74b7",
   "metadata": {},
   "source": [
    "# Transformation / Engineering (Logic Phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94c664",
   "metadata": {},
   "source": [
    "# Reporting / AI (Output Phase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
